# Vervet Accelerometer Classification
Repository containing data and code for comparing the effect of pre-processing and model choice on behavioural classification from accelerometer data in vervets.  

The repository has the following folder structure:  
├── data/  
│ ├── output/  
│ ├── raw/  
│ └── temp/  
├── models/  
├── plots/  
├── scripts/  
├── .gitignore   
├── environment_tabpfn.yml  
├── environment_torch_tabular.yml  
├── environment_tsai.yml  
├── README.md  
└── VervetBehClass.Rproj  
  
### Setting up the python environments
The YML files starting with environment can be used to recreate the various environments for running the deep learning packages in python.  
An easy way to get started is to use [mamba](https://mamba.readthedocs.io/en/latest/index.html).  
You can refer to the following [page](https://mamba.readthedocs.io/en/latest/user_guide/mamba.html#conda-yaml-spec-files) for creating an environment from the YML files.  

### Data folder
The data folder contains all the raw data needed to run the scripts. The various sub-folders include:  
- [raw](/data/raw/):  
    + [acc](/data/raw/acc/): Contains the raw accelerometer data. Subfolders are present for each of the four burst length and within each subfolder, there are 3 files for each orientation correction type. The uncorrected datasets for the burst lengths are obtained by running the script [01a_burst_division.R](/scripts/01a_burst_division.R) on the whole dataset. The daily and basal orientation corrected datasets are obtained by running the script [01b_orientation_correction.R](/scripts/01b_orientation_correction.R) on the whole dataset. Due to space considerations the entire dataset is not in this repository but can be found on movebank.   
    + [features](/data/raw/features/): Contains the features extracted from the accelerometer data. Subfolders are present for each burst length and within each subfolder, there are 3 files for each orientation correction type. The feature extraction pipeline template is provided in the script [01c_feature_calculation.R](/scripts/01c_feature_calculation.R) and can be run on the raw accelerometer data.  
    + [annotations](/data/raw/annotations/): Contains CSVs with the behavioural attribution for each sample within each burst. There is one file per burst and a merged file which assigns one behavioural attribute to a sample based on a majority rule implemented in [03_combine_burst_attributions.ipynb](/scripts/03_combine_burst_attributions.ipynb).  
    + [focal_sampling](/data/raw/focal_sampling/): Contains CSVs with the actual dates used for the focal sampling ([focal_sampled_days.csv](/data/raw/focal_sampling/focal_sampled_days.csv)) and the proportion of behaviour from the focal sampling ([prop_behaviour_monthly_focal](/data/raw/focal_sampling/prop_behaviour_monthly_focal.csv)). The raw data and the features data are too large for the repo and will be made available on request.  
    + [annotated_burst_id_lookup_table.csv](/data/raw/annotated_burst_id_lookup_table.csv): A lookup table matching burst_id with new_burst values to match bursts across burst length datasets.  
    + [clean_burst_ids.csv](/data/raw/clean_burst_ids.csv): A CSV containing a list of IDs which only have a single behaviour attributed to the whole burst.  
- [temp](/data/temp/):  
    + [acc_tsai](/data/temp/acc_tsai/): Contains the the raw accelerometer data converted into a format for use in the tsai package for running the deep-learning timeseries based classifiers. The conversion is in the script and takes the raw accelerometer data as input [03_combine_burst_attributions.ipynb](/scripts/03_combine_burst_attributions.ipynb). Subfolders are present for each burst length and within each subfolder, there are 3 files for each orientation correction type.  
    + [annotations](/data/temp/annotations/): Temporary CSV files used to identify outliers in resting based on VeDBA and then remove these outliers from the final training dataset. They are output from the scripts [02_vedba_outliers.R](/scripts/02_vedba_outliers.R) and [03_combine_burst_attributions.ipynb](/scripts/03_combine_burst_attributions.ipynb).  
    + [focal_sampling](/data/temp/focal_sampling/): Temporary CSV files output for the identification of ays to extract accelerometer data from for comparison with focal sampling in the script [11_focal_sampling_days.R](/scripts/11_focal_sampling_days.R).  
    + [plotting](/data/temp/plotting/) and [statistical_analysis](/data/temp/statistical_analysis/): Temporary CSV files for plotting and statistical analysis.  
- [output](/data/output/):  
    + [behaviour_comparison](/data/output/behaviour_comparison/): Model metrics and confusion matrix data from the different models. These are output from the scripts [04_feature_classification_ml.ipynb](/scripts/04_feature_classification_ml.ipynb), [05_feature_classification_dl.ipynb](/scripts/05_feature_classification_dl.ipynb), [06_feature_classification_dl_tabpfn.ipynb](/scripts/06_feature_classification_dl_tabpfn.ipynb) and [07_timeseries_classification_dl.ipynb](/scripts/07_timeseries_classification_dl.ipynb).  
    + [focal_sampling_predictions](/data/output/focal_sampling_predictions/): Parquet files with the behaviour predictions for the bursts subset for comparisons with the focal sampling data. These are output from the scripts [12a_final_models_acc_inference.ipynb](/scripts/12a_final_models_acc_inference.ipynb) and [12b_final_models_features_inference.ipynb](/scripts/12b_final_models_features_inference.ipynb).  
    + [statistical_analysis](/data/output/statistical_analysis/): CSVs containing the results of the statistical comparisons (anova, marginal means, contrasts) for the different experiments. These are output from the scripts [08_statistics_global_metrics.R](/scripts/08_statistics_global_metrics.R), [09_statistics_behaviour_metrics.R](/scripts/09_statistics_behaviour_metrics.R) and [13_statistics_focal_sampling_comparison.R](/scripts/13_statistics_focal_sampling_comparison.R).  

### Scripts
The [scripts](/scripts/) folder contains the Jupyter notebooks and R files needed to run the training of the models, the statistical comparisons in the experiments, the inference on new data and produce the various plots. They are numbered and must be run in order to replicate the whole study. All the scripts are commented with details on how to run them. Briefly, the various steps involved are:  
1. **Create the training datasets**: This involves taking the original burst 1 uncorrected raw accelerometer data and creating 12 datasets (4 burst lengths * 3 correction types). Then the selected features are extracted for each of these datasets. The functions to do this are: [01a_burst_division.R](/scripts/01a_burst_division.R), [01b_orientation_correction.R](/scripts/01b_orientation_correction.R) and [01c_feature_calculation.R](/scripts/01c_feature_calculation.R). These are to be run on the entire 1.5 year dataset. Due to space considerations the entire dataset is not in this repository but can be found on movebank. These scripts are not *needed* to replicate the study as their output datasets are already provided in the various subfolders in the [raw data folder](/data/raw/).  
2. **Assign behaviour to bursts**: We use a simple majority rule after removing extra behavioural classes to assign a single behavioural class (out of 8 classes) to each burst in the datasets. We also rmeove outliers in *'Resting'* based on VeDBA values. The scripts to do this are: [02_vedba_outliers.R](/scripts/02_vedba_outliers.R) and [03_combine_burst_attributions.ipynb](/scripts/03_combine_burst_attributions.ipynb).  
3. **Train machine and deep learning models**: This step involves training the 9 different models on each of the datasets, with each mdoel trained for 5 different seeds. The scripts to do this are: [04_feature_classification_ml.ipynb](/scripts/04_feature_classification_ml.ipynb), [05_feature_classification_dl.ipynb](/scripts/05_feature_classification_dl.ipynb), [06_feature_classification_dl_tabpfn.ipynb](/scripts/06_feature_classification_dl_tabpfn.ipynb) and [07_timeseries_classification_dl.ipynb](/scripts/07_timeseries_classification_dl.ipynb). The results of the model training are output to the [behaviour comparison folder](/data/output/behaviour_comparison/).  
4. **Statistical analysis of Experiments 1,2 and 3**: We statistically compare the effect of burst length, orientation correction and model algorithm choice on the global model metrics and the precision and recall of behavioural categories. The scripts involved are: [08_statistics_global_metrics.R](/scripts/08_statistics_global_metrics.R) and [09_statistics_behaviour_metrics.R](/scripts/09_statistics_behaviour_metrics.R). We also use the results of experiment 3 to identify the two best performing model and use them for the next steps. The results are output to the [statistical analysis folder](/data/output/statistical_analysis/).  
5. **Save best performing models for inference**: This steps involves saving the trained models on to the disk for later reuse. We choose 2 of the best performing models - *HydraMultiROCKET trained on burst 1 uncorrected data* and *TabPFN trained on burst 4 data with basal correction*. The scripts involved are: [10a_final_models_acc.ipynb](/scripts/10a_final_models_acc.ipynb) and [10b_final_models_features.ipynb](/scripts/10b_final_models_features.ipynb). The models are output to the [models folder](/models/).  
6. **Run inference on new data**: We reload the models saved before and use them to run inference on new data for comparing with the focal sampling. The scripts involved are: [12a_final_models_acc_inference.ipynb](/scripts/12a_final_models_acc_inference.ipynb) and [12b_final_models_features_inference.ipynb](/scripts/12b_final_models_features_inference.ipynb). The specific month and day for which the inference is run is randomly chosen from the months with the most focal sampling data and uses the [11_focal_sampling_days.R](/scripts/11_focal_sampling_days.R) script. Once the days are shortlisted, we subset these speciific dates from the whole dataset which is not in this reposiitory. The shortlisted data is too large to be uploaded and can be made available on request. The results of the inference are output to the [focal sampling predictions folder](/data/output/focal_sampling_predictions/).  
7. **Statistical comparison of model predictions with focal sampling**: We compare the proportion of behaviours inferred from the 2 models with the proportion of behaviours from the focal sampling data. the script for this step is [13_statistics_focal_sampling_comparison.R](/scripts/13_statistics_focal_sampling_comparison.R). The results are output to the [statistical analysis folder](/data/output/statistical_analysis/).  
8. **Plot the results**: These scripts are used to create various plots to visualise the effect of the different comparisons in the experiments. The scripts involved are: [14a_publication_plots_fig1.R](/scripts/14a_publication_plots_fig1.R), [14b_publication_plots_fig2.R](/scripts/14b_publication_plots_fig2.R), [14c_publication_plots_fig3,4.R](/scripts/14c_publication_plots_fig3,4.R), [14d_publication_plots_fig5.R](/scripts/14d_publication_plots_fig5.R) and [14e_publication_plots_supplementary.R](/scripts/14e_publication_plots_supplementary.R). the plots are output into the [plots folder](/plots/).  
