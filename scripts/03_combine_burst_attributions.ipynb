{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script we will:  \n",
    "1. Attribute a single behaviour to an acceleration sample based on majority rule  \n",
    "2. Identify outlier samples in resting based on VeDBA values and remove these from the training data  \n",
    "3. Create the correct parquet files for use in the [tsai](https://timeseriesai.github.io/tsai/data.preparation.html) package  \n",
    "\n",
    "The behavioral attribution is based on annotations in the [./data/raw/annotations/](./data/raw/annotations) folder.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain burst attribution based on majority rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in new behavioural annotations data\n",
    "annotations_burst1 = pd.read_csv(\n",
    "    \"../data/raw/annotations/annotations_burst1.csv\"\n",
    ")\n",
    "annotations_burst1[\"burst\"] = \"burst_1\"\n",
    "annotations_burst2 = pd.read_csv(\n",
    "    \"../data/raw/annotations/annotations_burst2.csv\"\n",
    ")\n",
    "annotations_burst2[\"burst\"] = \"burst_2\"\n",
    "annotations_burst3 = pd.read_csv(\n",
    "    \"../data/raw/annotations/annotations_burst3.csv\"\n",
    ")\n",
    "annotations_burst3[\"burst\"] = \"burst_3\"\n",
    "annotations_burst4 = pd.read_csv(\n",
    "    \"../data/raw/annotations/annotations_burst4.csv\"\n",
    ")\n",
    "annotations_burst4[\"burst\"] = \"burst_4\"\n",
    "\n",
    "# Combine all annotations\n",
    "annotations_combined = pd.concat(\n",
    "    [annotations_burst1, annotations_burst2, annotations_burst3, annotations_burst4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain unique value counts for the behaviours\n",
    "annotations_combined[\"Final_behaviour\"].value_counts()\n",
    "# List of 20 behaviours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bursts which have been attributed to specific behaviours\n",
    "beh_remove = [\n",
    "    \"Out of sight\",\n",
    "    \"Other\",\n",
    "    \"Mating\",\n",
    "    \"Vigilant\",\n",
    "    \"Male inspection\",\n",
    "    \"Social\",\n",
    "    \"Aggressive display\",\n",
    "    \"Jumping\",\n",
    "]\n",
    "# Note that this means we are conservative with the data we keep for analysis. If a burst has e.g., 10 Resting, 5 Eating, 7 Out of sight and 4 Vigilant, it will be removed as the Removed category will be ther majority (7+4 = 11) and greater than the Resting category (10). This should help reduce noise in the data.\n",
    "\n",
    "annotations_combined[\"attribution_merged\"] = annotations_combined[\"Final_behaviour\"]\n",
    "\n",
    "# Add tag remove to the behaviours in beh_remove\n",
    "annotations_combined.loc[\n",
    "    annotations_combined[\"attribution_merged\"].isin(beh_remove), \"attribution_merged\"\n",
    "] = \"Remove\"\n",
    "\n",
    "# Combine specific behaviours\n",
    "# Foraging ground and canopy to eating\n",
    "annotations_combined.loc[\n",
    "    (annotations_combined[\"attribution_merged\"] == \"Foraging ground\")\n",
    "    | (annotations_combined[\"attribution_merged\"] == \"Foraging canopy\"),\n",
    "    \"attribution_merged\",\n",
    "] = \"Eating\"\n",
    "\n",
    "# Running, Aggression to Active\n",
    "annotations_combined.loc[\n",
    "    (annotations_combined[\"attribution_merged\"] == \"Running\")\n",
    "    | (annotations_combined[\"attribution_merged\"] == \"Aggression\"),\n",
    "    \"attribution_merged\",\n",
    "] = \"Running\"\n",
    "\n",
    "# Canopy movement to Walking\n",
    "annotations_combined.loc[\n",
    "    annotations_combined[\"attribution_merged\"] == \"Canopy movement\",\n",
    "    \"attribution_merged\",\n",
    "] = \"Walking\"\n",
    "\n",
    "# Value counts of the attribution_merged column\n",
    "annotations_combined[\"attribution_merged\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by burst, Ind_ID, new_burst and get the majority behaviour in a dataframe\n",
    "annotations_majority = (\n",
    "    annotations_combined.groupby([\"burst\", \"Ind_ID\", \"new_burst\"])[\"attribution_merged\"]\n",
    "    .agg(lambda x: x.value_counts().index[0])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Obtain value counts for each burst separately\n",
    "print(\"\\nValue counts per burst:\")\n",
    "for burst in annotations_majority[\"burst\"].unique():\n",
    "    print(f\"\\n{burst}:\")\n",
    "    print(\n",
    "        annotations_majority[annotations_majority[\"burst\"] == burst][\n",
    "            \"attribution_merged\"\n",
    "        ].value_counts()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of bursts which are being removed from the dataset per burst\n",
    "# Group by burst and calculate proportion of \"Remove\" for each burst\n",
    "(\n",
    "    annotations_majority.groupby(\"burst\").apply(\n",
    "        lambda x: (x[\"attribution_merged\"] == \"Remove\").mean()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Around 16% of the data is being removed from each burst dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the annotations_majority dataframe\n",
    "annotations_majority.to_csv(\n",
    "    \"../data/raw/annotations/attributions_merged_majority.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortlist bursts with VeDBA > 0.1\n",
    "\n",
    "We use a threshold of 0.1 to remove outlier Resting bursts based on visual inspection of the VeDBA values across all bursts. See [R file](02_vedba_outliers.R)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features parquet files and subset bursts with vedba values less than 0.1\n",
    "# Load a sample file to check\n",
    "pq_file_path = (\n",
    "    \"../data/raw/features/Burst_1/annotated_features_burst_1_uncorrected.parquet\"\n",
    ")\n",
    "feat = pd.read_parquet(\n",
    "    pq_file_path,\n",
    "    engine=\"pyarrow\",\n",
    "    filters=[(\"mean_vedba\", \">\", 0.1)],\n",
    "    # Select only the columns we need\n",
    "    columns=[\"Ind_ID\", \"new_burst\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run over all features parquet files\n",
    "features_dir = \"../data/raw/features/\"\n",
    "# Get all parquet files even in sub directories\n",
    "pq_files = glob.glob(os.path.join(features_dir, \"**\", \"*.parquet\"), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run loop over all files to shortlist the bursts with vedba values less than 0.1\n",
    "all_shortlist = []\n",
    "for pq_file_path in pq_files:\n",
    "    # Load the parquet file\n",
    "    feat = pd.read_parquet(\n",
    "        pq_file_path,\n",
    "        engine=\"pyarrow\",\n",
    "        filters=[(\"mean_vedba\", \">\", 0.1)],\n",
    "        # Select only the columns we need\n",
    "        columns=[\"Ind_ID\", \"new_burst\"],\n",
    "    )\n",
    "\n",
    "    if not feat.empty:\n",
    "        # Extract metadata from filename\n",
    "        file_name = os.path.basename(pq_file_path)\n",
    "        burst = file_name.split(\"_\")[3]\n",
    "        correction_type = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "        # Add metadata columns\n",
    "        feat[\"burst\"] = \"burst_\" + burst\n",
    "        feat[\"correction_type\"] = correction_type\n",
    "\n",
    "        # Reorder columns\n",
    "        feat = feat[[\"burst\", \"correction_type\", \"Ind_ID\", \"new_burst\"]]\n",
    "\n",
    "        # Add to results list\n",
    "        all_shortlist.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into one df\n",
    "combined_shortlist = pd.concat(all_shortlist, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the shortlist\n",
    "combined_shortlist.to_csv(\n",
    "    \"../data/temp/annotations/shortlist_bursts_vedba_01.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify burst attribution based on outlier\n",
    "We need to identify resting bursts with vedba greater than 0.1 and then convert these to removed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load attributions data\n",
    "annotations_combined = pd.read_csv(\n",
    "    \"../data/temp/annotations/attributions_merged_majority.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load outlier information\n",
    "outlier_info = pd.read_csv(\"../data/temp/annotations/shortlist_bursts_vedba_01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach attribution information to outlier dataset\n",
    "outlier_info = outlier_info.merge(\n",
    "    annotations_combined[[\"Ind_ID\", \"new_burst\", \"attribution_merged\"]],\n",
    "    on=[\"Ind_ID\", \"new_burst\"],\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only from uncorrected as it is the raw data\n",
    "outlier_info = outlier_info[\n",
    "    outlier_info[\"correction_type\"] == \"uncorrected\"\n",
    "]\n",
    "outlier_info = outlier_info[[\"burst\", \"Ind_ID\", \"new_burst\"]].drop_duplicates()\n",
    "# 366 bursts to be removed across"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets\n",
    "annotations_outliers = annotations_combined.merge(\n",
    "    outlier_info, how=\"left\", on=[\"burst\", \"Ind_ID\", \"new_burst\"], indicator=True\n",
    ")\n",
    "\n",
    "# Add Remove label to Resting outliers\n",
    "annotations_outliers[\"attribution_merged\"] = annotations_outliers.apply(\n",
    "    lambda x: \"Remove\"\n",
    "    if x[\"_merge\"] == \"both\" and x[\"attribution_merged\"] == \"Resting\"\n",
    "    else x[\"attribution_merged\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Drop merge indicator and return\n",
    "annotations_outliers.drop(\"_merge\", axis=1, inplace=True)\n",
    "\n",
    "# Value counts\n",
    "annotations_outliers.attribution_merged.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Active/Inactive attribution\n",
    "We will use Resting, Sleeping and Grooming receiver as Inactive behaviours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of inactive behaviours\n",
    "inactive_beh = [\"Resting\", \"Sleeping\", \"Grooming receiver\"]\n",
    "# Create new column for activity, ensuring that Remove columns remain as Remove\n",
    "annotations_outliers[\"activity\"] = annotations_outliers.apply(\n",
    "    lambda x: \"Remove\"\n",
    "    if x[\"attribution_merged\"] == \"Remove\"\n",
    "    else \"Inactive\"\n",
    "    if x[\"attribution_merged\"] in inactive_beh\n",
    "    else \"Active\",\n",
    "    axis=1,\n",
    ")\n",
    "annotations_outliers.activity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an id column combining Ind_ID and new_burst\n",
    "annotations_outliers[\"id\"] = (\n",
    "    annotations_outliers[\"Ind_ID\"].astype(str)\n",
    "    + \"_\"\n",
    "    + annotations_outliers[\"new_burst\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the final dataframe\n",
    "annotations_outliers.to_csv(\n",
    "    \"../data/temp/annotations/attributions_merged_majority_outliers.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify accelerometer data for tsai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all parquet files even in sub directories\n",
    "acc_dir = \"../data/raw/acc/\"\n",
    "acc_files = glob.glob(os.path.join(acc_dir, \"**\", \"*.parquet\"), recursive=True)\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"../data/temp/acc_tsai\"\n",
    "\n",
    "for pq_file_name in acc_files:\n",
    "    # Load the parquet file\n",
    "    acc = pd.read_parquet(\n",
    "        pq_file_name,\n",
    "        engine=\"pyarrow\",\n",
    "    )\n",
    "    # First melt the X, Y, Z columns into a feature column\n",
    "    acc_melted = pd.melt(\n",
    "        acc,\n",
    "        id_vars=[\n",
    "            \"Ind_ID\",\n",
    "            \"burst_id\",\n",
    "            \"new_burst\",\n",
    "            \"burst_start_time\",\n",
    "            \"sample_number\",\n",
    "        ],\n",
    "        value_vars=[\"X\", \"Y\", \"Z\"],\n",
    "        var_name=\"feature\",\n",
    "        value_name=\"value\",\n",
    "    )\n",
    "    # Then pivot to get sample_number as columns\n",
    "    acc_wide_alt = acc_melted.pivot_table(\n",
    "        index=[\n",
    "            \"Ind_ID\",\n",
    "            \"burst_id\",\n",
    "            \"new_burst\",\n",
    "            \"burst_start_time\",\n",
    "            \"feature\",\n",
    "        ],\n",
    "        columns=\"sample_number\",\n",
    "        values=\"value\",\n",
    "    )\n",
    "    # Rename columns to be just the numbers\n",
    "    acc_wide_alt.columns = [str(col) for col in acc_wide_alt.columns]\n",
    "    # Reset index\n",
    "    acc_wide_alt = acc_wide_alt.reset_index()\n",
    "    # Remove burst_id and burst-start_time columns\n",
    "    acc_wide_alt.drop([\"burst_id\", \"burst_start_time\"], axis=1, inplace=True)\n",
    "    # Identify Burst from filename\n",
    "    file_name = os.path.basename(pq_file_name)\n",
    "    burst = file_name.split(\"_\")[3]\n",
    "    # Add burst info to output dir\n",
    "    burst_output_dir = f\"{output_dir}/Burst_{burst}/\"\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(burst_output_dir, exist_ok=True)\n",
    "    # Replace _acc_ with _acc_tsai_ in the filename\n",
    "    file_name = file_name.replace(\"_acc_\", \"_acc_tsai_\")\n",
    "    # output file name\n",
    "    output_file_name = os.path.join(burst_output_dir, file_name)\n",
    "    # Save the dataframe to a parquet file\n",
    "    acc_wide_alt.to_parquet(\n",
    "        output_file_name,\n",
    "        index=False,\n",
    "        engine=\"pyarrow\",\n",
    "    )\n",
    "    print(f\"Saved {output_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output file\n",
    "output_file_name = (\n",
    "    \"../data/temp/acc_tsai/Burst_1/annotated_acc_tsai_burst_1_rotbasal.parquet\"\n",
    ")\n",
    "acc_check = pd.read_parquet(\n",
    "    output_file_name,\n",
    "    engine=\"pyarrow\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
